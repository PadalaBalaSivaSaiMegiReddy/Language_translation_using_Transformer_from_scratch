{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ3KyTfKQ6IP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goFfSWscQ_F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16590754-b1e6-46c3-ace1-cc343ac721dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor Flow Version: 2.12.0\n",
            "\n",
            "GPU is AVAILABLE\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
        "print()\n",
        "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
        "print(\"GPU is\", \"AVAILABLE\" if gpu else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing the data"
      ],
      "metadata": {
        "id": "gBqTjLf1wOx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the data"
      ],
      "metadata": {
        "id": "v1C8088TwRZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# path = path if os.path.exists(path) else \".{}\".format(path)\n",
        "# file_path = os.path.join(path, \"language-translation-englishfrench\", \"/content/drive/MyDrive/eng_-french.csv\")\n",
        "file_path ='/content/eng_-french.csv'\n",
        "\n",
        "# read the data\n",
        "df = pd.read_csv(file_path)\n",
        "df['source'] = df['English words/sentences']\n",
        "\n",
        "# let's add an initial “seed” token ([start]) and a stop token ([end]) to each target sentence.\n",
        "df['target'] = df['French words/sentences'].apply(lambda x: '[start] ' + x + ' [end]')\n",
        "df = df.drop(['English words/sentences', 'French words/sentences'], axis=1)\n",
        "\n",
        "# display a few random samples\n",
        "df.sample(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yA-OXY1dRS6B",
        "outputId": "937873a2-cef6-4e31-9440-39cf15ac579b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     source  \\\n",
              "45106                Where are my trousers?   \n",
              "80861          Are you looking for someone?   \n",
              "112637     Will you please show me the way?   \n",
              "77323           It's none of your business.   \n",
              "126299  She assumed an air of indifference.   \n",
              "\n",
              "                                                   target  \n",
              "45106           [start] Où se trouve mon pantalon ? [end]  \n",
              "80861               [start] Tu cherches quelqu'un ? [end]  \n",
              "112637  [start] Me montreras-tu le chemin, s'il te pla...  \n",
              "77323          [start] Ce ne sont pas tes affaires. [end]  \n",
              "126299      [start] Elle a pris un air indifférent. [end]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a04abe8-15d8-47f9-b453-774b43448ec7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45106</th>\n",
              "      <td>Where are my trousers?</td>\n",
              "      <td>[start] Où se trouve mon pantalon ? [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80861</th>\n",
              "      <td>Are you looking for someone?</td>\n",
              "      <td>[start] Tu cherches quelqu'un ? [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112637</th>\n",
              "      <td>Will you please show me the way?</td>\n",
              "      <td>[start] Me montreras-tu le chemin, s'il te pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77323</th>\n",
              "      <td>It's none of your business.</td>\n",
              "      <td>[start] Ce ne sont pas tes affaires. [end]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126299</th>\n",
              "      <td>She assumed an air of indifference.</td>\n",
              "      <td>[start] Elle a pris un air indifférent. [end]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a04abe8-15d8-47f9-b453-774b43448ec7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a04abe8-15d8-47f9-b453-774b43448ec7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a04abe8-15d8-47f9-b453-774b43448ec7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling the data and splitting it into train, validation, and test sets"
      ],
      "metadata": {
        "id": "_qQbXm_DwXDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_tokens parameter - \n",
        "sequence lenght - "
      ],
      "metadata": {
        "id": "RTeCRL6Qwo84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the data\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# split the data into train, validation, and test sets\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.2)\n",
        "test_size = int(len(df) * 0.1)\n",
        "\n",
        "train_df = df[:train_size]\n",
        "val_df = df[train_size:train_size+val_size]\n",
        "test_df = df[train_size+val_size:]\n",
        "\n",
        "# display the data sets representations using a pie chart just to see the distribution of the data\n",
        "labels = 'Train', 'Validation', 'Test'\n",
        "sizes = [len(train_df), len(val_df), len(test_df)]\n",
        "explode = (0.1, 0, 0)\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
        "ax1.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "5c04n2WYSus7",
        "outputId": "a2ab9b6f-bd4a-4384-c704-570cd724ded7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardizing, tokenizing and indexing the data"
      ],
      "metadata": {
        "id": "z4sIIAg-waVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 25000\n",
        "sequence_length = 30\n",
        "\n",
        "# define a custom standardization function that convert to lowercase and strips all punctuations except \"[\" and \"]\" (so we can tell apart \"start\" from \"[start]\").\n",
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        " \n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "# tokenize the data using our custom standardization function\n",
        "source_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "# index all tokens in the source and target sentences\n",
        "train_source_texts = train_df['source'].values\n",
        "train_target_texts = train_df['target'].values\n",
        "source_vectorization.adapt(train_source_texts)\n",
        "target_vectorization.adapt(train_target_texts)"
      ],
      "metadata": {
        "id": "kyMJe52PS71y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a random sample before and after vectorization just to test the vectorization\n",
        "random_sample = random.randint(0, len(train_df))\n",
        "print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
        "print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
        "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
        "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
        "\n",
        "# display the decoding of the vectorized text (from vector back to text) just to test the vectorization\n",
        "source_decoded_text = ''\n",
        "for i in range(len(source_vectorization(train_source_texts[random_sample]))):\n",
        "    source_decoded_text += source_vectorization.get_vocabulary()[source_vectorization(train_source_texts[random_sample])[i]] + ' '\n",
        "print(\"Source decoded texts (one random sample):\", source_decoded_text)\n",
        "target_decoded_text = ''\n",
        "for i in range(len(target_vectorization(train_target_texts[random_sample]))):\n",
        "    target_decoded_text += target_vectorization.get_vocabulary()[target_vectorization(train_target_texts[random_sample])[i]] + ' '\n",
        "print(\"Target decoded texts (one random sample):\", target_decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XWTDC6-TJ6q",
        "outputId": "f9f56a52-6604-4caa-99c6-ade34cf6f0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source texts (one random sample): It's very clean.\n",
            "Target texts (one random sample): [start] C'est très propre. [end]\n",
            "Source vectors (one random sample): tf.Tensor(\n",
            "[ 47  54 599   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0], shape=(30,), dtype=int64)\n",
            "Target vectors (one random sample): tf.Tensor(\n",
            "[  2  29  53 614   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(31,), dtype=int64)\n",
            "Source decoded texts (one random sample): its very clean                            \n",
            "Target decoded texts (one random sample): [start] cest très propre [end]                           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display the shape of our vectorized data\n",
        "train_source_vectors = source_vectorization(train_source_texts)\n",
        "train_target_vectors = target_vectorization(train_target_texts)\n",
        "print(\"Source vectors (shape):\", train_source_vectors.shape)\n",
        "print(\"Target vectors (shape):\", train_target_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdE7k9igTXso",
        "outputId": "a82312f9-4653-4f3d-c5e4-23a976882c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source vectors (shape): (122934, 30)\n",
            "Target vectors (shape): (122934, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Transformer\n",
        "Positional Embedding"
      ],
      "metadata": {
        "id": "U2Cn-5PoxI8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim) # token embedding layer\n",
        "        self.position_embeddings = tf.keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # position embedding layer\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedded_tokens = self.token_embeddings(inputs) # embed the tokens\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
        "        embedded_positions = self.position_embeddings(positions) \n",
        "        # embed the positions \n",
        "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"input_dim\": self.input_dim,\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "G3btPF2XTXpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a random sample before and after embbeding just to test our class\n",
        "\n",
        "embed_dim = 256\n",
        "train_source_embedded = PositionalEmbedding(\n",
        "    sequence_length=sequence_length,\n",
        "    input_dim=max_tokens,\n",
        "    output_dim=embed_dim,\n",
        "    name=\"source_embedding\",\n",
        ") (train_source_vectors)\n",
        "\n",
        "train_target_embedded = PositionalEmbedding(\n",
        "    sequence_length=sequence_length,\n",
        "    input_dim=max_tokens,\n",
        "    output_dim=embed_dim,\n",
        "    name=\"target_embedding\",\n",
        ") (train_source_vectors)\n",
        "\n",
        "random_sample = random.randint(0, len(train_df))\n",
        "print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
        "print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
        "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
        "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
        "print(\"Source embedded vectors (one random sample):\", train_source_embedded[random_sample])\n",
        "print(\"Target embedded vectors (one random sample):\", train_target_embedded[random_sample])"
      ],
      "metadata": {
        "id": "74lVsX76TXmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4694b716-edfd-4787-f322-2679bee61e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source texts (one random sample): Is the school on this side of the river?\n",
            "Target texts (one random sample): [start] Est-ce que l'école est de ce côté de la rivière ? [end]\n",
            "Source vectors (one random sample): tf.Tensor(\n",
            "[  7   5 161  33  14 785  12   5 680   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0], shape=(30,), dtype=int64)\n",
            "Target vectors (one random sample): tf.Tensor(\n",
            "[   2   81    7  217   15    5   17  473    5   10 7193    3    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0], shape=(31,), dtype=int64)\n",
            "Source embedded vectors (one random sample): tf.Tensor(\n",
            "[[-0.03575045  0.00688008 -0.05422808 ... -0.09192665 -0.05659594\n",
            "  -0.02424612]\n",
            " [ 0.05053169  0.03264599 -0.0571413  ... -0.00876415  0.00909493\n",
            "  -0.09554061]\n",
            " [-0.00118278  0.02178463  0.01152462 ...  0.02620129  0.0029407\n",
            "  -0.05680144]\n",
            " ...\n",
            " [ 0.0136307   0.03146141  0.01165657 ... -0.05878459 -0.05308883\n",
            "   0.00865269]\n",
            " [ 0.04181018 -0.00565334 -0.02330199 ... -0.07107943  0.01188804\n",
            "  -0.00084232]\n",
            " [ 0.08709629 -0.01374204  0.02567553 ... -0.0434212  -0.02798757\n",
            "   0.03241391]], shape=(30, 256), dtype=float32)\n",
            "Target embedded vectors (one random sample): tf.Tensor(\n",
            "[[-0.00058928 -0.03342858 -0.07130072 ... -0.0002     -0.04495467\n",
            "  -0.00382657]\n",
            " [ 0.01144039 -0.071211   -0.03300607 ...  0.04235953 -0.00169957\n",
            "  -0.02311405]\n",
            " [ 0.08250492  0.00632177 -0.05011978 ... -0.00184779  0.01706692\n",
            "   0.08522455]\n",
            " ...\n",
            " [ 0.02885743  0.04146061  0.02961761 ... -0.01533862  0.01089246\n",
            "   0.02743454]\n",
            " [-0.0346993   0.00951035  0.03584491 ...  0.04013022  0.01635653\n",
            "  -0.05465078]\n",
            " [-0.01740991  0.0169573   0.00113933 ... -0.01503538 -0.03543378\n",
            "  -0.04402897]], shape=(30, 256), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display the shape of our embedded data just to test the class\n",
        "print(\"Source embedded vectors (shape):\", train_source_embedded.shape)\n",
        "print(\"Target embedded vectors (shape):\", train_target_embedded.shape)"
      ],
      "metadata": {
        "id": "6bK6_9gDTXjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05412ae9-f13b-4d98-a119-5760a7ed3ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source embedded vectors (shape): (122934, 30, 256)\n",
            "Target embedded vectors (shape): (122934, 30, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Attention mechanism**\n",
        "\n",
        "Causal Masking"
      ],
      "metadata": {
        "id": "ocSr3qPX2H8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# credits to OpenAI for that one (https://github.com/openai/gpt-2/blob/master/src/model.py)\n",
        "\n",
        "def shape_list(x):\n",
        "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
        "    static = x.shape.as_list()\n",
        "    dynamic = tf.shape(x)\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "def attention_mask(nd, ns, *, dtype):\n",
        "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
        "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
        "    \"\"\"\n",
        "    i = tf.range(nd)[:,None]\n",
        "    j = tf.range(ns)\n",
        "    m = i >= j - ns + nd\n",
        "    return tf.cast(m, dtype)\n",
        "def mask_attn_weights(w):\n",
        "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
        "    _, _, nd, ns = shape_list(w)\n",
        "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
        "    b = tf.reshape(b, [1, 1, nd, ns])\n",
        "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
        "    return w"
      ],
      "metadata": {
        "id": "4GudWQz_vVyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the causal masking of a random tensor just to test the function\n",
        "random_tensor = tf.random.uniform(shape=(1, 1, 5, 5), minval=0, maxval=1, dtype=tf.float32)\n",
        "print(\"Masked attention weights:\", mask_attn_weights(random_tensor))"
      ],
      "metadata": {
        "id": "y2T131VtvVuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95792dc5-c1ca-46c6-dd49-36ff2dc057a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masked attention weights: tf.Tensor(\n",
            "[[[[ 3.5926497e-01 -1.0000000e+10 -1.0000000e+10 -1.0000000e+10\n",
            "    -1.0000000e+10]\n",
            "   [ 1.0210156e-02  4.6676528e-01 -1.0000000e+10 -1.0000000e+10\n",
            "    -1.0000000e+10]\n",
            "   [ 4.6962190e-01  7.4541569e-03  5.0332975e-01 -1.0000000e+10\n",
            "    -1.0000000e+10]\n",
            "   [ 5.2242863e-01  9.3802702e-01  2.2934878e-01  6.6834188e-01\n",
            "    -1.0000000e+10]\n",
            "   [ 8.6922121e-01  8.5046291e-02  3.9657211e-01  9.4453347e-01\n",
            "     2.1551991e-01]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaled Dot-Product Attention"
      ],
      "metadata": {
        "id": "PBNYYjto2TOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
        "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
        "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
        "    if use_causal_mask:\n",
        "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
        "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
        "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
        "    return output"
      ],
      "metadata": {
        "id": "hefSYKzovVq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the shape of our attention output just to test the function\n",
        "input = train_source_embedded\n",
        "input = tf.expand_dims(input, axis=1)\n",
        "print(\"Scaled dot product attention (shape):\", scaled_dot_product_attention(input, input, input, use_causal_mask=True).shape)"
      ],
      "metadata": {
        "id": "Edp84E_YvVmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c042a18-0639-459f-8d01-97e8572374f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled dot product attention (shape): (122934, 1, 30, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Head Attention"
      ],
      "metadata": {
        "id": "3clvgjIk2X29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, h, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.h = h\n",
        "        if embed_dim % h != 0:\n",
        "            raise ValueError(\n",
        "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
        "            )\n",
        "        self.q_linear = tf.keras.layers.Dense(embed_dim)\n",
        "        self.k_linear = tf.keras.layers.Dense(embed_dim)\n",
        "        self.v_linear = tf.keras.layers.Dense(embed_dim)\n",
        "        self.concat_linear = tf.keras.layers.Dense(embed_dim)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def concat_heads(self, x, batch_size):\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
        "\n",
        "    def call(self, q, k, v, use_causal_mask=False):\n",
        "        batch_size = tf.shape(k)[0]\n",
        "        q = self.q_linear(q)\n",
        "        k = self.k_linear(k)\n",
        "        v = self.v_linear(v)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
        "        concat = self.concat_heads(attention, batch_size)\n",
        "        concat = self.concat_linear(concat)\n",
        "        return concat\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(MultiHeadAttention, self).get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"h\": self.h,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "rtcYVRqHvVip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Encoder**"
      ],
      "metadata": {
        "id": "s020qFMd2ea7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
        "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
        "        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
        "        self.feed_forward = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embed_dim),]\n",
        "        )\n",
        "        \n",
        "    def call(self, x):\n",
        "        # Post layer normalization + residual connections\n",
        "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
        "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "j6Bnu6HYvuBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Decoder**"
      ],
      "metadata": {
        "id": "wyMmIzMr2k2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
        "        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
        "        self.feed_forward = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
        "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
        "        self.layer_norm_3 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, x, context):\n",
        "        # Post layer normalization + residual connections\n",
        "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
        "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
        "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "Jo77jpLwvt_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting it all together**"
      ],
      "metadata": {
        "id": "v9vde0Ps2rSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "def format_dataset(source, target):\n",
        "    source_vectors = source_vectorization(source)\n",
        "    target_vectors = target_vectorization(target)\n",
        "    return ({\n",
        "        \"source\": source_vectors, # encoder_inputs\n",
        "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
        "    }, target_vectors[:, 1:]) # decoder_outputs\n",
        "\n",
        "def make_dataset(df):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].values, df[\"target\"].values))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_df)\n",
        "val_ds = make_dataset(val_df)"
      ],
      "metadata": {
        "id": "_O9OkScXvt7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the shape of the first batch of data in the dataset just to see what it looks like\n",
        "for batch in train_ds.take(1):\n",
        "    print(\"Encoder Inputs:\", batch[0][\"source\"].shape)\n",
        "    print(\"Decoder Inputs:\", batch[0][\"target\"].shape)\n",
        "    print(\"Decoder Outputs:\", batch[1].shape)"
      ],
      "metadata": {
        "id": "pULIy27fvt46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edaee48-a8b4-4bcf-9ac0-a809af1fee75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Inputs: (64, 30)\n",
            "Decoder Inputs: (64, 30)\n",
            "Decoder Outputs: (64, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 512 # dimension of the embedding space\n",
        "dense_dim = 2048 # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\n",
        "num_heads = 8\n",
        "\n",
        "# the transformer body\n",
        "encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
        "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
        "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "\n",
        "# the transformer head\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs = tf.keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "cJd0rsPlv3F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the Transformer"
      ],
      "metadata": {
        "id": "VjdhEbJz2yzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's translate a few random test sentences with our newly-trained Transformer.\n",
        "\n"
      ],
      "metadata": {
        "id": "2U8x1tSV27Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "EPOCHS = 50\n",
        "checkpoint_filepath = '/tmp/checkpoint/'\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.1,\n",
        "        patience=3,\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=6,\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True\n",
        "    ),\n",
        "]\n",
        "    \n",
        "transformer.fit(train_ds, \n",
        "                epochs=EPOCHS, \n",
        "                callbacks=callbacks_list,\n",
        "                validation_data=val_ds)\n",
        "\n",
        "transformer.load_weights(checkpoint_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeoWz1sm217u",
        "outputId": "4a22b5fb-7fa0-4e66-c42a-70b289efdb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1921/1921 [==============================] - 268s 132ms/step - loss: 0.9549 - accuracy: 0.8574 - val_loss: 0.6031 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "1921/1921 [==============================] - 237s 123ms/step - loss: 0.5689 - accuracy: 0.9024 - val_loss: 0.4909 - val_accuracy: 0.9112 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "1921/1921 [==============================] - 238s 124ms/step - loss: 0.4706 - accuracy: 0.9141 - val_loss: 0.4624 - val_accuracy: 0.9150 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "1203/1921 [=================>............] - ETA: 1:16 - loss: 0.4211 - accuracy: 0.9204"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Transformer"
      ],
      "metadata": {
        "id": "KFkrqFkLCl6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_vocab = target_vectorization.get_vocabulary()\n",
        "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
        "max_decoded_sentence_length = 30\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = target_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "# let's translate 50 random sentences\n",
        "for i in range(50):\n",
        "    random_index = np.random.randint(0, len(test_df))\n",
        "    input_sentence = test_df[\"source\"].iloc[random_index]\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))\n",
        "    print()"
      ],
      "metadata": {
        "id": "Y62F5FMvCCM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHrZ7lKnCoan"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}